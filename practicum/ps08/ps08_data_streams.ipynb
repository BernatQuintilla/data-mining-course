{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice Session 08: Data streams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: <font color=\"blue\">Bernat Quintilla Castell√≥n</font>\n",
    "\n",
    "E-mail: <font color=\"blue\">bernat.quintilla01@estudiant.upf.edu</font>\n",
    "\n",
    "Date: <font color=\"blue\">26/11/2023</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import nltk\n",
    "import gzip\n",
    "import random\n",
    "import statistics\n",
    "import secrets\n",
    "import re\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Dataset and how to iterate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave this code as-is\n",
    "\n",
    "INPUT_FILE = \"movie_lines.tsv.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave this code as-is\n",
    "\n",
    "# Producer in Python that reads a filename by words\n",
    "def read_by_words(filename, max_words=-1, report_every=-1):\n",
    "    \n",
    "    # Open the input file\n",
    "    with gzip.open(INPUT_FILE, \"rt\", encoding='utf8') as file:\n",
    "        \n",
    "        # Initialize counter of words to stop at max_words\n",
    "        counter = 0\n",
    "    \n",
    "        # Regular expression to identify words having 3 letters or more and beginning with a-z\n",
    "        word_expr = re.compile('^[a-z]{2,}$', re.IGNORECASE)\n",
    "\n",
    "        # Iterate through lines in the file\n",
    "        for line in file:\n",
    "            \n",
    "            elements = line.split(\"\\t\")\n",
    "            \n",
    "            text = \"\"\n",
    "            if len(elements) >= 5:\n",
    "                text = elements[4].strip()\n",
    "                                        \n",
    "            if counter > max_words and max_words != -1:\n",
    "                break\n",
    "                \n",
    "            for word in nltk.word_tokenize(text):\n",
    "                          \n",
    "                if word_expr.match(word):\n",
    "                    counter += 1\n",
    "                    \n",
    "                    # Report\n",
    "                    if (report_every != -1) and (counter % report_every == 0):\n",
    "                        if max_words == -1:\n",
    "                            print(\"- Read %d words so far\" % (counter))\n",
    "                        else:\n",
    "                            print(\"- Read %d/%d words so far\" % (counter, max_words))\n",
    "\n",
    "                    # Produce the word in lowercase\n",
    "                    yield word.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current word 'may'\n",
      "Current word 'cop'\n",
      "Current word 'my'\n",
      "Current word 'girl'\n",
      "Current word 'do'\n",
      "Current word 'the'\n",
      "Current word 'not'\n",
      "Current word 'talk'\n",
      "Current word 'friend'\n",
      "Current word 'to'\n",
      "Current word 'it'\n",
      "Current word 'something'\n",
      "- Read 100000/300000 words so far\n",
      "Current word 'be'\n",
      "Current word 'involved'\n",
      "Current word 'you'\n",
      "Current word 'one'\n",
      "Current word 'highest'\n",
      "Current word 'most'\n",
      "Current word 'you'\n",
      "Current word 'he'\n",
      "Current word 'told'\n",
      "Current word 'if'\n",
      "Current word 'camp'\n",
      "- Read 200000/300000 words so far\n",
      "Current word 'evening'\n",
      "Current word 'of'\n",
      "Current word 'begin'\n",
      "Current word 'lydia'\n",
      "Current word 'another'\n",
      "Current word 'choice'\n",
      "Current word 'marry'\n",
      "Current word 'vector'\n",
      "Current word 'he'\n",
      "Current word 'just'\n",
      "- Read 300000/300000 words so far\n"
     ]
    }
   ],
   "source": [
    "# Leave this code as-is\n",
    "\n",
    "# Iterate through the file\n",
    "for word in read_by_words(INPUT_FILE, max_words=300000, report_every=100000):\n",
    "    # Prints 1/10000 of words\n",
    "    if random.random() < 0.0001:\n",
    "        print(\"Current word '%s'\" % (word)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this if above gives an error about 'punkt'\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Determine approximately the top-10 words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Replace this cell with your code for \"add_reservoir\"</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_reservoir(reservoir, item, max_reservoir_size):\n",
    "    # YOUR CODE HERE\n",
    "    if len(reservoir) < max_reservoir_size:\n",
    "        reservoir.append(item)\n",
    "    else:\n",
    "        item_to_remove = random.choice(reservoir)\n",
    "        reservoir.remove(item_to_remove)\n",
    "        reservoir.append(item)\n",
    "    assert(len(reservoir) <= max_reservoir_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Replace this cell with your code for \"reservoir_sampling\"</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reservoir_sampling(filename, reservoir_size, max_words=-1, report_every=-1):\n",
    "    reservoir = []\n",
    "    words_read = 0\n",
    "\n",
    "    for word in read_by_words(filename, max_words=max_words, report_every=report_every):\n",
    "        words_read += 1\n",
    "\n",
    "        #Reservoir sampling\n",
    "        if len(reservoir) < reservoir_size:\n",
    "            #If reservoir is not full add word directly\n",
    "            reservoir.append(word)\n",
    "        else:\n",
    "            #Reservoir is full\n",
    "            #Probability of replacing an existing word is reservoir_size/words_read\n",
    "            replace_probability = reservoir_size / words_read\n",
    "\n",
    "            if random.random() < replace_probability:\n",
    "                add_to_reservoir(reservoir, word, reservoir_size)\n",
    "\n",
    "    return words_read, reservoir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Read 100000/1000000 words so far\n",
      "- Read 200000/1000000 words so far\n",
      "- Read 300000/1000000 words so far\n",
      "- Read 400000/1000000 words so far\n",
      "- Read 500000/1000000 words so far\n",
      "- Read 600000/1000000 words so far\n",
      "- Read 700000/1000000 words so far\n",
      "- Read 800000/1000000 words so far\n",
      "- Read 900000/1000000 words so far\n",
      "- Read 1000000/1000000 words so far\n",
      "Number of items seen    : 1000023\n",
      "Number of items sampled : 1500\n"
     ]
    }
   ],
   "source": [
    "# Leave this code as-is\n",
    "\n",
    "reservoir_size = 1500\n",
    "(items_seen, reservoir) = reservoir_sampling(INPUT_FILE, reservoir_size, max_words=1000000, report_every=100000)\n",
    "\n",
    "print(\"Number of items seen    : %d\" % items_seen)\n",
    "print(\"Number of items sampled : %d\" % len(reservoir) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53 you\n",
      "50 the\n",
      "39 to\n",
      "32 that\n",
      "26 and\n",
      "25 do\n",
      "23 what\n",
      "20 of\n",
      "19 it\n",
      "18 was\n"
     ]
    }
   ],
   "source": [
    "# Leave this code as-is\n",
    "\n",
    "freq = {}\n",
    "for item in reservoir:\n",
    "    freq[item] = reservoir.count(item)\n",
    "\n",
    "most_frequent_items = sorted([(frequency, word) for word, frequency in freq.items()], reverse=True)[:10]\n",
    "for absolute_frequency, word in most_frequent_items:\n",
    "    print(\"%d %s\" % (absolute_frequency, word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Replace this cell with your code to print the top items and their relative frequencies</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53 you (3.53%)\n",
      "50 the (3.33%)\n",
      "39 to (2.60%)\n",
      "32 that (2.13%)\n",
      "26 and (1.73%)\n",
      "25 do (1.67%)\n",
      "23 what (1.53%)\n",
      "20 of (1.33%)\n",
      "19 it (1.27%)\n",
      "18 was (1.20%)\n",
      "16 this (1.07%)\n",
      "16 me (1.07%)\n",
      "16 know (1.07%)\n",
      "14 is (0.93%)\n",
      "13 we (0.87%)\n"
     ]
    }
   ],
   "source": [
    "#Compute total count of items in the reservoir\n",
    "total_items = len(reservoir)\n",
    "\n",
    "#Compute and print top 15 most frequent items and their relative frequencies\n",
    "top_items = sorted([(frequency, word) for word, frequency in freq.items()], reverse=True)[:15]\n",
    "\n",
    "for absolute_frequency, word in top_items:\n",
    "    relative_frequency = (absolute_frequency / total_items) * 100\n",
    "    print(\"%d %s (%.2f%%)\" % (absolute_frequency, word, relative_frequency))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Increase the max limit of words so that one pass takes no more than 5 minutes to be completed. Replace this cell with your code to try different reservoir sizes. In each case, print your estimate for the relative and absolute frequency of the words in the entire dataset.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reservoir Size: 50\n",
      "========================================\n",
      "- Read 100000/300000 words so far\n",
      "- Read 200000/300000 words so far\n",
      "- Read 300000/300000 words so far\n",
      "you:\n",
      "  Absolute Frequency: 53\n",
      "  Relative Frequency: 0.02%\n",
      "  Estimated Frequency in Entire Dataset: 318000.00\n",
      "\n",
      "the:\n",
      "  Absolute Frequency: 50\n",
      "  Relative Frequency: 0.02%\n",
      "  Estimated Frequency in Entire Dataset: 300000.00\n",
      "\n",
      "to:\n",
      "  Absolute Frequency: 39\n",
      "  Relative Frequency: 0.01%\n",
      "  Estimated Frequency in Entire Dataset: 234000.00\n",
      "\n",
      "that:\n",
      "  Absolute Frequency: 32\n",
      "  Relative Frequency: 0.01%\n",
      "  Estimated Frequency in Entire Dataset: 192000.00\n",
      "\n",
      "and:\n",
      "  Absolute Frequency: 26\n",
      "  Relative Frequency: 0.01%\n",
      "  Estimated Frequency in Entire Dataset: 156000.00\n",
      "\n",
      "\n",
      "Reservoir Size: 100\n",
      "========================================\n",
      "- Read 100000/300000 words so far\n",
      "- Read 200000/300000 words so far\n",
      "- Read 300000/300000 words so far\n",
      "you:\n",
      "  Absolute Frequency: 53\n",
      "  Relative Frequency: 0.02%\n",
      "  Estimated Frequency in Entire Dataset: 159000.00\n",
      "\n",
      "the:\n",
      "  Absolute Frequency: 50\n",
      "  Relative Frequency: 0.02%\n",
      "  Estimated Frequency in Entire Dataset: 150000.00\n",
      "\n",
      "to:\n",
      "  Absolute Frequency: 39\n",
      "  Relative Frequency: 0.01%\n",
      "  Estimated Frequency in Entire Dataset: 117000.00\n",
      "\n",
      "that:\n",
      "  Absolute Frequency: 32\n",
      "  Relative Frequency: 0.01%\n",
      "  Estimated Frequency in Entire Dataset: 96000.00\n",
      "\n",
      "and:\n",
      "  Absolute Frequency: 26\n",
      "  Relative Frequency: 0.01%\n",
      "  Estimated Frequency in Entire Dataset: 78000.00\n",
      "\n",
      "\n",
      "Reservoir Size: 500\n",
      "========================================\n",
      "- Read 100000/300000 words so far\n",
      "- Read 200000/300000 words so far\n",
      "- Read 300000/300000 words so far\n",
      "you:\n",
      "  Absolute Frequency: 53\n",
      "  Relative Frequency: 0.02%\n",
      "  Estimated Frequency in Entire Dataset: 31800.00\n",
      "\n",
      "the:\n",
      "  Absolute Frequency: 50\n",
      "  Relative Frequency: 0.02%\n",
      "  Estimated Frequency in Entire Dataset: 30000.00\n",
      "\n",
      "to:\n",
      "  Absolute Frequency: 39\n",
      "  Relative Frequency: 0.01%\n",
      "  Estimated Frequency in Entire Dataset: 23400.00\n",
      "\n",
      "that:\n",
      "  Absolute Frequency: 32\n",
      "  Relative Frequency: 0.01%\n",
      "  Estimated Frequency in Entire Dataset: 19200.00\n",
      "\n",
      "and:\n",
      "  Absolute Frequency: 26\n",
      "  Relative Frequency: 0.01%\n",
      "  Estimated Frequency in Entire Dataset: 15600.00\n",
      "\n",
      "\n",
      "Reservoir Size: 1000\n",
      "========================================\n",
      "- Read 100000/300000 words so far\n",
      "- Read 200000/300000 words so far\n",
      "- Read 300000/300000 words so far\n",
      "you:\n",
      "  Absolute Frequency: 53\n",
      "  Relative Frequency: 0.02%\n",
      "  Estimated Frequency in Entire Dataset: 15900.00\n",
      "\n",
      "the:\n",
      "  Absolute Frequency: 50\n",
      "  Relative Frequency: 0.02%\n",
      "  Estimated Frequency in Entire Dataset: 15000.00\n",
      "\n",
      "to:\n",
      "  Absolute Frequency: 39\n",
      "  Relative Frequency: 0.01%\n",
      "  Estimated Frequency in Entire Dataset: 11700.00\n",
      "\n",
      "that:\n",
      "  Absolute Frequency: 32\n",
      "  Relative Frequency: 0.01%\n",
      "  Estimated Frequency in Entire Dataset: 9600.00\n",
      "\n",
      "and:\n",
      "  Absolute Frequency: 26\n",
      "  Relative Frequency: 0.01%\n",
      "  Estimated Frequency in Entire Dataset: 7800.00\n",
      "\n",
      "\n",
      "Reservoir Size: 5000\n",
      "========================================\n",
      "- Read 100000/300000 words so far\n",
      "- Read 200000/300000 words so far\n",
      "- Read 300000/300000 words so far\n",
      "you:\n",
      "  Absolute Frequency: 53\n",
      "  Relative Frequency: 0.02%\n",
      "  Estimated Frequency in Entire Dataset: 3180.00\n",
      "\n",
      "the:\n",
      "  Absolute Frequency: 50\n",
      "  Relative Frequency: 0.02%\n",
      "  Estimated Frequency in Entire Dataset: 3000.00\n",
      "\n",
      "to:\n",
      "  Absolute Frequency: 39\n",
      "  Relative Frequency: 0.01%\n",
      "  Estimated Frequency in Entire Dataset: 2340.00\n",
      "\n",
      "that:\n",
      "  Absolute Frequency: 32\n",
      "  Relative Frequency: 0.01%\n",
      "  Estimated Frequency in Entire Dataset: 1920.00\n",
      "\n",
      "and:\n",
      "  Absolute Frequency: 26\n",
      "  Relative Frequency: 0.01%\n",
      "  Estimated Frequency in Entire Dataset: 1560.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Function to estimate the frequency in the entire dataset\n",
    "def estimate_frequency(absolute_frequency, dataset_size, reservoir_size):\n",
    "    return (absolute_frequency * dataset_size) / reservoir_size\n",
    "\n",
    "reservoir_sizes = [50, 100, 500, 1000, 5000]\n",
    "\n",
    "#Iterate over different reservoir sizes\n",
    "for reservoir_size in reservoir_sizes:\n",
    "    print(f\"\\nReservoir Size: {reservoir_size}\\n{'=' * 40}\")\n",
    "\n",
    "    #Perform reservoir sampling\n",
    "    words_read, reservoir = reservoir_sampling(INPUT_FILE, reservoir_size, max_words=300000, report_every=100000)\n",
    "\n",
    "    #Compute total count of items in entire dataset\n",
    "    total_dataset_size = words_read * (300000 / words_read)\n",
    "\n",
    "    #Compute and print top 5 most frequent items and their estimates\n",
    "    top_items = sorted([(frequency, word) for word, frequency in freq.items()], reverse=True)[:5]\n",
    "\n",
    "    for absolute_frequency, word in top_items:\n",
    "        relative_frequency = (absolute_frequency / words_read) * 100\n",
    "        estimated_frequency = estimate_frequency(absolute_frequency, total_dataset_size, reservoir_size)\n",
    "\n",
    "        print(f\"{word}:\")\n",
    "        print(f\"  Absolute Frequency: {absolute_frequency}\")\n",
    "        print(f\"  Relative Frequency: {relative_frequency:.2f}%\")\n",
    "        print(f\"  Estimated Frequency in Entire Dataset: {estimated_frequency:.2f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Remove the max limit of words and re-run. Replace this cell with a brief commentary indicating what reservoir size you would recommend to use, and your overall conclusions.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reservoir Size: 50\n",
      "========================================\n",
      "- Read 100000 words so far\n",
      "- Read 200000 words so far\n",
      "- Read 300000 words so far\n",
      "- Read 400000 words so far\n",
      "- Read 500000 words so far\n",
      "- Read 600000 words so far\n",
      "- Read 700000 words so far\n",
      "- Read 800000 words so far\n",
      "- Read 900000 words so far\n",
      "- Read 1000000 words so far\n",
      "- Read 1100000 words so far\n",
      "- Read 1200000 words so far\n",
      "- Read 1300000 words so far\n",
      "- Read 1400000 words so far\n",
      "- Read 1500000 words so far\n",
      "- Read 1600000 words so far\n",
      "- Read 1700000 words so far\n",
      "- Read 1800000 words so far\n",
      "- Read 1900000 words so far\n",
      "- Read 2000000 words so far\n",
      "- Read 2100000 words so far\n",
      "- Read 2200000 words so far\n",
      "- Read 2300000 words so far\n",
      "- Read 2400000 words so far\n",
      "- Read 2500000 words so far\n",
      "- Read 2600000 words so far\n",
      "- Read 2700000 words so far\n",
      "- Read 2800000 words so far\n",
      "- Read 2900000 words so far\n",
      "you:\n",
      "  Absolute Frequency: 53\n",
      "  Relative Frequency: 0.00%\n",
      "  Estimated Frequency in Entire Dataset: 318000.00\n",
      "\n",
      "the:\n",
      "  Absolute Frequency: 50\n",
      "  Relative Frequency: 0.00%\n",
      "  Estimated Frequency in Entire Dataset: 300000.00\n",
      "\n",
      "to:\n",
      "  Absolute Frequency: 39\n",
      "  Relative Frequency: 0.00%\n",
      "  Estimated Frequency in Entire Dataset: 234000.00\n",
      "\n",
      "that:\n",
      "  Absolute Frequency: 32\n",
      "  Relative Frequency: 0.00%\n",
      "  Estimated Frequency in Entire Dataset: 192000.00\n",
      "\n",
      "and:\n",
      "  Absolute Frequency: 26\n",
      "  Relative Frequency: 0.00%\n",
      "  Estimated Frequency in Entire Dataset: 156000.00\n",
      "\n",
      "\n",
      "Reservoir Size: 100\n",
      "========================================\n",
      "- Read 100000 words so far\n",
      "- Read 200000 words so far\n",
      "- Read 300000 words so far\n",
      "- Read 400000 words so far\n",
      "- Read 500000 words so far\n",
      "- Read 600000 words so far\n",
      "- Read 700000 words so far\n",
      "- Read 800000 words so far\n",
      "- Read 900000 words so far\n",
      "- Read 1000000 words so far\n",
      "- Read 1100000 words so far\n",
      "- Read 1200000 words so far\n",
      "- Read 1300000 words so far\n",
      "- Read 1400000 words so far\n",
      "- Read 1500000 words so far\n",
      "- Read 1600000 words so far\n",
      "- Read 1700000 words so far\n",
      "- Read 1800000 words so far\n",
      "- Read 1900000 words so far\n",
      "- Read 2000000 words so far\n",
      "- Read 2100000 words so far\n",
      "- Read 2200000 words so far\n",
      "- Read 2300000 words so far\n",
      "- Read 2400000 words so far\n",
      "- Read 2500000 words so far\n",
      "- Read 2600000 words so far\n",
      "- Read 2700000 words so far\n",
      "- Read 2800000 words so far\n",
      "- Read 2900000 words so far\n",
      "you:\n",
      "  Absolute Frequency: 53\n",
      "  Relative Frequency: 0.00%\n",
      "  Estimated Frequency in Entire Dataset: 159000.00\n",
      "\n",
      "the:\n",
      "  Absolute Frequency: 50\n",
      "  Relative Frequency: 0.00%\n",
      "  Estimated Frequency in Entire Dataset: 150000.00\n",
      "\n",
      "to:\n",
      "  Absolute Frequency: 39\n",
      "  Relative Frequency: 0.00%\n",
      "  Estimated Frequency in Entire Dataset: 117000.00\n",
      "\n",
      "that:\n",
      "  Absolute Frequency: 32\n",
      "  Relative Frequency: 0.00%\n",
      "  Estimated Frequency in Entire Dataset: 96000.00\n",
      "\n",
      "and:\n",
      "  Absolute Frequency: 26\n",
      "  Relative Frequency: 0.00%\n",
      "  Estimated Frequency in Entire Dataset: 78000.00\n",
      "\n",
      "\n",
      "Reservoir Size: 500\n",
      "========================================\n",
      "- Read 100000 words so far\n",
      "- Read 200000 words so far\n",
      "- Read 300000 words so far\n",
      "- Read 400000 words so far\n",
      "- Read 500000 words so far\n",
      "- Read 600000 words so far\n",
      "- Read 700000 words so far\n",
      "- Read 800000 words so far\n",
      "- Read 900000 words so far\n",
      "- Read 1000000 words so far\n",
      "- Read 1100000 words so far\n",
      "- Read 1200000 words so far\n",
      "- Read 1300000 words so far\n",
      "- Read 1400000 words so far\n",
      "- Read 1500000 words so far\n",
      "- Read 1600000 words so far\n",
      "- Read 1700000 words so far\n",
      "- Read 1800000 words so far\n",
      "- Read 1900000 words so far\n",
      "- Read 2000000 words so far\n",
      "- Read 2100000 words so far\n",
      "- Read 2200000 words so far\n",
      "- Read 2300000 words so far\n",
      "- Read 2400000 words so far\n",
      "- Read 2500000 words so far\n",
      "- Read 2600000 words so far\n",
      "- Read 2700000 words so far\n",
      "- Read 2800000 words so far\n",
      "- Read 2900000 words so far\n",
      "you:\n",
      "  Absolute Frequency: 53\n",
      "  Relative Frequency: 0.00%\n",
      "  Estimated Frequency in Entire Dataset: 31800.00\n",
      "\n",
      "the:\n",
      "  Absolute Frequency: 50\n",
      "  Relative Frequency: 0.00%\n",
      "  Estimated Frequency in Entire Dataset: 30000.00\n",
      "\n",
      "to:\n",
      "  Absolute Frequency: 39\n",
      "  Relative Frequency: 0.00%\n",
      "  Estimated Frequency in Entire Dataset: 23400.00\n",
      "\n",
      "that:\n",
      "  Absolute Frequency: 32\n",
      "  Relative Frequency: 0.00%\n",
      "  Estimated Frequency in Entire Dataset: 19200.00\n",
      "\n",
      "and:\n",
      "  Absolute Frequency: 26\n",
      "  Relative Frequency: 0.00%\n",
      "  Estimated Frequency in Entire Dataset: 15600.00\n",
      "\n",
      "\n",
      "Reservoir Size: 1000\n",
      "========================================\n",
      "- Read 100000 words so far\n",
      "- Read 200000 words so far\n",
      "- Read 300000 words so far\n",
      "- Read 400000 words so far\n",
      "- Read 500000 words so far\n",
      "- Read 600000 words so far\n",
      "- Read 700000 words so far\n",
      "- Read 800000 words so far\n",
      "- Read 900000 words so far\n",
      "- Read 1000000 words so far\n",
      "- Read 1100000 words so far\n",
      "- Read 1200000 words so far\n",
      "- Read 1300000 words so far\n",
      "- Read 1400000 words so far\n",
      "- Read 1500000 words so far\n",
      "- Read 1600000 words so far\n",
      "- Read 1700000 words so far\n",
      "- Read 1800000 words so far\n",
      "- Read 1900000 words so far\n",
      "- Read 2000000 words so far\n",
      "- Read 2100000 words so far\n",
      "- Read 2200000 words so far\n",
      "- Read 2300000 words so far\n",
      "- Read 2400000 words so far\n",
      "- Read 2500000 words so far\n",
      "- Read 2600000 words so far\n",
      "- Read 2700000 words so far\n",
      "- Read 2800000 words so far\n",
      "- Read 2900000 words so far\n",
      "you:\n",
      "  Absolute Frequency: 53\n",
      "  Relative Frequency: 0.00%\n",
      "  Estimated Frequency in Entire Dataset: 15900.00\n",
      "\n",
      "the:\n",
      "  Absolute Frequency: 50\n",
      "  Relative Frequency: 0.00%\n",
      "  Estimated Frequency in Entire Dataset: 15000.00\n",
      "\n",
      "to:\n",
      "  Absolute Frequency: 39\n",
      "  Relative Frequency: 0.00%\n",
      "  Estimated Frequency in Entire Dataset: 11700.00\n",
      "\n",
      "that:\n",
      "  Absolute Frequency: 32\n",
      "  Relative Frequency: 0.00%\n",
      "  Estimated Frequency in Entire Dataset: 9600.00\n",
      "\n",
      "and:\n",
      "  Absolute Frequency: 26\n",
      "  Relative Frequency: 0.00%\n",
      "  Estimated Frequency in Entire Dataset: 7800.00\n",
      "\n",
      "\n",
      "Reservoir Size: 5000\n",
      "========================================\n",
      "- Read 100000 words so far\n",
      "- Read 200000 words so far\n",
      "- Read 300000 words so far\n",
      "- Read 400000 words so far\n",
      "- Read 500000 words so far\n",
      "- Read 600000 words so far\n",
      "- Read 700000 words so far\n",
      "- Read 800000 words so far\n",
      "- Read 900000 words so far\n",
      "- Read 1000000 words so far\n",
      "- Read 1100000 words so far\n",
      "- Read 1200000 words so far\n",
      "- Read 1300000 words so far\n",
      "- Read 1400000 words so far\n",
      "- Read 1500000 words so far\n",
      "- Read 1600000 words so far\n",
      "- Read 1700000 words so far\n",
      "- Read 1800000 words so far\n",
      "- Read 1900000 words so far\n",
      "- Read 2000000 words so far\n",
      "- Read 2100000 words so far\n",
      "- Read 2200000 words so far\n",
      "- Read 2300000 words so far\n",
      "- Read 2400000 words so far\n",
      "- Read 2500000 words so far\n",
      "- Read 2600000 words so far\n",
      "- Read 2700000 words so far\n",
      "- Read 2800000 words so far\n",
      "- Read 2900000 words so far\n",
      "you:\n",
      "  Absolute Frequency: 53\n",
      "  Relative Frequency: 0.00%\n",
      "  Estimated Frequency in Entire Dataset: 3180.00\n",
      "\n",
      "the:\n",
      "  Absolute Frequency: 50\n",
      "  Relative Frequency: 0.00%\n",
      "  Estimated Frequency in Entire Dataset: 3000.00\n",
      "\n",
      "to:\n",
      "  Absolute Frequency: 39\n",
      "  Relative Frequency: 0.00%\n",
      "  Estimated Frequency in Entire Dataset: 2340.00\n",
      "\n",
      "that:\n",
      "  Absolute Frequency: 32\n",
      "  Relative Frequency: 0.00%\n",
      "  Estimated Frequency in Entire Dataset: 1920.00\n",
      "\n",
      "and:\n",
      "  Absolute Frequency: 26\n",
      "  Relative Frequency: 0.00%\n",
      "  Estimated Frequency in Entire Dataset: 1560.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove the max limit on words\n",
    "max_words = -1\n",
    "\n",
    "#Use of the same code as the previous cell of code\n",
    "#Iterate over different reservoir sizes\n",
    "for reservoir_size in reservoir_sizes:\n",
    "    print(f\"\\nReservoir Size: {reservoir_size}\\n{'=' * 40}\")\n",
    "\n",
    "    #Perform reservoir sampling\n",
    "    words_read, reservoir = reservoir_sampling(INPUT_FILE, reservoir_size, max_words=max_words, report_every=100000)\n",
    "\n",
    "    #Compute total count of items in entire dataset\n",
    "    total_dataset_size = words_read * (300000 / words_read)\n",
    "\n",
    "    #Compute and print top 5 most frequent items and their estimates\n",
    "    top_items = sorted([(frequency, word) for word, frequency in freq.items()], reverse=True)[:5]\n",
    "\n",
    "    for absolute_frequency, word in top_items:\n",
    "        relative_frequency = (absolute_frequency / words_read) * 100\n",
    "        estimated_frequency = estimate_frequency(absolute_frequency, total_dataset_size, reservoir_size)\n",
    "\n",
    "        print(f\"{word}:\")\n",
    "        print(f\"  Absolute Frequency: {absolute_frequency}\")\n",
    "        print(f\"  Relative Frequency: {relative_frequency:.2f}%\")\n",
    "        print(f\"  Estimated Frequency in Entire Dataset: {estimated_frequency:.2f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the given dataset, it seems that even a relatively small reservoir size (50 for example) provides some level of stability in the top words. A reservoir size around 50 or 100 is the one I would recommend. It provides stability in the top words while potentially ensuring faster processing within the one-hour time limit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Determine approximately the distinct number of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave this code as-is\n",
    "\n",
    "def count_trailing_zeroes(number):\n",
    "    count = 0\n",
    "    while number & 1 == 0:\n",
    "        count += 1\n",
    "        number = number >> 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave this code as-is\n",
    "\n",
    "def random_hash_function():\n",
    "    # We use a cryptographically safe generator for the salt of our hash function\n",
    "    salt = secrets.token_bytes(32)\n",
    "    return lambda string: hash(string + str(salt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Replace this cell with your code to perform the requested number of passes.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate on pass 1: 65536 distinct words\n",
      "Estimate on pass 2: 524288 distinct words\n",
      "Estimate on pass 3: 1048576 distinct words\n",
      "Estimate on pass 4: 65536 distinct words\n",
      "Estimate on pass 5: 524288 distinct words\n"
     ]
    }
   ],
   "source": [
    "number_of_passes = 5\n",
    "estimates = []\n",
    "for i in range(number_of_passes):\n",
    "    #For each pass new hash function\n",
    "    hash_function = random_hash_function()\n",
    "\n",
    "    max_trailing_zeroes = 0\n",
    "\n",
    "    #Iterate through lines in file\n",
    "    with gzip.open(INPUT_FILE, \"rt\", encoding='utf8') as file:\n",
    "        for line in file:\n",
    "            elements = line.split(\"\\t\")\n",
    "            text = \"\"\n",
    "            if len(elements) >= 5:\n",
    "                text = elements[4].strip()\n",
    "\n",
    "            #Hash text with hash function\n",
    "            hash_value = hash_function(text)\n",
    "\n",
    "            #Count trailing zeroes\n",
    "            trailing_zeroes = count_trailing_zeroes(hash_value)\n",
    "\n",
    "            # Update maximum trailing zeros\n",
    "            max_trailing_zeroes = max(max_trailing_zeroes, trailing_zeroes)\n",
    "\n",
    "    #2^R as the estimate for the number of distinct elements\n",
    "    estimate = 2 ** max_trailing_zeroes\n",
    "    estimates.append(estimate)\n",
    "\n",
    "    print(\"Estimate on pass %d: %d distinct words\" % (i+1, estimate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Average of estimates: 445644.8\n",
      "* Median  of estimates: 524288.0\n"
     ]
    }
   ],
   "source": [
    "# Leave this code as-is\n",
    "\n",
    "print(\"* Average of estimates: %.1f\" % statistics.mean(estimates))\n",
    "print(\"* Median of estimates: %.1f\" % statistics.median(estimates))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Remove the limit of max words, or set to a high number, but notice that you do no need to use more than one hour of computer processing time, and perform the 10 passes. Replace this cell with the results you obtained in each pass, and whether the average or the median seem more appropriate for this probabilistic counting.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run  1 :\n",
      "Estimate on pass 1: 4194304 distinct words\n",
      "Estimate on pass 2: 262144 distinct words\n",
      "Estimate on pass 3: 131072 distinct words\n",
      "Estimate on pass 4: 1048576 distinct words\n",
      "Estimate on pass 5: 262144 distinct words\n",
      "Estimate on pass 6: 131072 distinct words\n",
      "Estimate on pass 7: 131072 distinct words\n",
      "Estimate on pass 8: 1048576 distinct words\n",
      "Estimate on pass 9: 262144 distinct words\n",
      "Estimate on pass 10: 2097152 distinct words\n",
      "Estimate on pass 11: 262144 distinct words\n",
      "Estimate on pass 12: 65536 distinct words\n",
      "Estimate on pass 13: 131072 distinct words\n",
      "Estimate on pass 14: 131072 distinct words\n",
      "Estimate on pass 15: 262144 distinct words\n",
      "Estimate on pass 16: 1048576 distinct words\n",
      "Estimate on pass 17: 524288 distinct words\n",
      "Estimate on pass 18: 262144 distinct words\n",
      "Estimate on pass 19: 131072 distinct words\n",
      "Estimate on pass 20: 262144 distinct words\n",
      "* Average of estimates: 632422.4\n",
      "* Median of estimates: 262144.0\n",
      "\n",
      "Run  2 :\n",
      "Estimate on pass 1: 524288 distinct words\n",
      "Estimate on pass 2: 4194304 distinct words\n",
      "Estimate on pass 3: 131072 distinct words\n",
      "Estimate on pass 4: 262144 distinct words\n",
      "Estimate on pass 5: 524288 distinct words\n",
      "Estimate on pass 6: 1048576 distinct words\n",
      "Estimate on pass 7: 262144 distinct words\n",
      "Estimate on pass 8: 131072 distinct words\n",
      "Estimate on pass 9: 524288 distinct words\n",
      "Estimate on pass 10: 131072 distinct words\n",
      "Estimate on pass 11: 262144 distinct words\n",
      "Estimate on pass 12: 65536 distinct words\n",
      "Estimate on pass 13: 524288 distinct words\n",
      "Estimate on pass 14: 262144 distinct words\n",
      "Estimate on pass 15: 524288 distinct words\n",
      "Estimate on pass 16: 262144 distinct words\n",
      "Estimate on pass 17: 8388608 distinct words\n",
      "Estimate on pass 18: 262144 distinct words\n",
      "Estimate on pass 19: 1048576 distinct words\n",
      "Estimate on pass 20: 131072 distinct words\n",
      "* Average of estimates: 973209.6\n",
      "* Median of estimates: 262144.0\n",
      "\n",
      "Run  3 :\n",
      "Estimate on pass 1: 524288 distinct words\n",
      "Estimate on pass 2: 131072 distinct words\n",
      "Estimate on pass 3: 131072 distinct words\n",
      "Estimate on pass 4: 262144 distinct words\n",
      "Estimate on pass 5: 262144 distinct words\n",
      "Estimate on pass 6: 8388608 distinct words\n",
      "Estimate on pass 7: 2097152 distinct words\n",
      "Estimate on pass 8: 262144 distinct words\n",
      "Estimate on pass 9: 65536 distinct words\n",
      "Estimate on pass 10: 131072 distinct words\n",
      "Estimate on pass 11: 131072 distinct words\n",
      "Estimate on pass 12: 32768 distinct words\n",
      "Estimate on pass 13: 524288 distinct words\n",
      "Estimate on pass 14: 2097152 distinct words\n",
      "Estimate on pass 15: 262144 distinct words\n",
      "Estimate on pass 16: 524288 distinct words\n",
      "Estimate on pass 17: 65536 distinct words\n",
      "Estimate on pass 18: 262144 distinct words\n",
      "Estimate on pass 19: 65536 distinct words\n",
      "Estimate on pass 20: 262144 distinct words\n",
      "* Average of estimates: 824115.2\n",
      "* Median of estimates: 262144.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Use of similar cell as previous\n",
    "number_of_passes = 20 #Set to 20\n",
    "for idx in range(3): #Do 3 separate runs\n",
    "    estimates = []\n",
    "    print('Run ',idx+1,':')\n",
    "    for i in range(number_of_passes):\n",
    "        #For each pass new hash function\n",
    "        hash_function = random_hash_function()\n",
    "\n",
    "        max_trailing_zeroes = 0\n",
    "\n",
    "        # Iterate through lines in file\n",
    "        with gzip.open(INPUT_FILE, \"rt\", encoding='utf8') as file:\n",
    "            for line in file:\n",
    "                elements = line.split(\"\\t\")\n",
    "                text = \"\"\n",
    "                #Limit of max words removed\n",
    "                text = elements[4].strip()\n",
    "\n",
    "                #Hash text with hash function\n",
    "                hash_value = hash_function(text)\n",
    "\n",
    "                # Count trailing zeroes\n",
    "                trailing_zeroes = count_trailing_zeroes(hash_value)\n",
    "\n",
    "                # Update maximum trailing zeros\n",
    "                max_trailing_zeroes = max(max_trailing_zeroes, trailing_zeroes)\n",
    "\n",
    "        #2^R as the estimate for the number of distinct elements\n",
    "        estimate = 2 ** max_trailing_zeroes\n",
    "        estimates.append(estimate)\n",
    "\n",
    "        print(\"Estimate on pass %d: %d distinct words\" % (i+1, estimate))\n",
    "\n",
    "    print(\"* Average of estimates: %.1f\" % statistics.mean(estimates))\n",
    "    print(\"* Median of estimates: %.1f\" % statistics.median(estimates))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By running the code with 20 passes instead of 5 and without a limit on the maximum number of words, the median is more consistent across the 3 runs, in fact all the runs have 262144 as the median. The increased number of passes allows the allgorithm to have better convergence in the estimation process. So I would choose this option as the more appropriate for this probabilistic counting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+2\" color=\"#003300\">I hereby declare that, except for the code provided by the course instructors, all of my code, report, and figures were produced by myself.</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
