{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice Session 03: Find near-duplicates using shingling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this session we will take a large corpus of tweets and detect near-duplicates on this corpus using a technique known as *shingling*.\n",
    "\n",
    "Two documents are considered near-duplicates if they share a large amount of ngrams. The *ngrams* of a phrase are overlapping sequences of words of length *n*. For instance, the phrase '*Never let them guess your next move.*' has the following 3-grams:\n",
    "\n",
    "* 'never let them'\n",
    "* 'let them guess'\n",
    "* 'them guess your'\n",
    "* 'guess your next'\n",
    "* 'your next move'\n",
    "\n",
    "To measure the similarity between two sets, we will use the [Jaccard index](https://en.wikipedia.org/wiki/Jaccard_index), which is the size of the intersection of the two sets divided by their union. This values goes between 0.0 (meaning the documents have no ngrams in common) to 1.0 (meaning the documents have the same ngrams).\n",
    "\n",
    "To speed up things, instead of comparing the set of shingles of two documents which can be large, we will derive a fixed-length *signature* or *sketch* for each document. This will be obtained by (1) applying a random permutation to the list of possible ngrams, and (2) pick the ngram that appears first in the permuted list. The Jaccard index between these signatures will be a good approximation of the Jaccard index between the original sets of ngrams. \n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: <font color=\"blue\">Bernat Quintilla Castellón</font>\n",
    "\n",
    "E-mail: <font color=\"blue\">bernat.quintilla01@estudiant.upf.edu</font>\n",
    "\n",
    "Date: <font color=\"blue\">The current date here</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Dataset\n",
    "\n",
    "The corpus you will use contains about 35,500 messages (\"tweets\") posted between March 13th, 2020, and March 14th, 2020, containing a hashtag or keyword related to COVID-19, and posted by a user declaring a location in Catalonia.\n",
    "\n",
    "The tweets are in a format known as [JSON](https://en.wikipedia.org/wiki/JSON#Example). Python's JSON library takes care of translating it into a dictionary.\n",
    "\n",
    "Then, the file is compressed using `gzip`, and can be compressed with the `gunzip` command, although we will read it in compressed form. The file is named `CovidLockdownCatalonia.json.gz`.\n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import json\n",
    "import gzip\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from timeit import default_timer as timer\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 10000 documents\n"
     ]
    }
   ],
   "source": [
    "# Input file\n",
    "INPUT_FILENAME = \"CovidLockdownCatalonia.json.gz\"\n",
    "\n",
    "# Array for storing messages\n",
    "messages = []\n",
    "MAX_MESSAGES = 10000\n",
    "\n",
    "with gzip.open(INPUT_FILENAME, \"rt\", encoding=\"utf-8\") as input_file:\n",
    "    \n",
    "    messages_read = 0\n",
    "    for line in input_file:\n",
    "            \n",
    "        # Read message\n",
    "        tweet = json.loads(line)\n",
    "\n",
    "        # Keep only messages in Catalan\n",
    "        if tweet[\"lang\"] == \"ca\":\n",
    "            \n",
    "            messages_read += 1\n",
    "            \n",
    "            if messages_read <= MAX_MESSAGES:\n",
    "                author = tweet[\"user\"][\"screen_name\"]\n",
    "                message = tweet[\"full_text\"]\n",
    "                messages.append(message)\n",
    "\n",
    "print(\"Read %d documents\" % len(messages))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Auxiliary functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the Jaccard similarity between two lists: the size of the intersection of two sets, divided by the size of their union.\n",
    "\n",
    "You can use set operations: `set(l)` to convert a list `l` to a set, then `set1.union(set2)` and `set1.intersection(set2)` to compute union and intersection of sets `set1`, `set2`. Learn more in this [tutorial on set operations](https://learnpython.com/blog/python-set-operations/)\n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Replace this cell with your code for function \"jaccard_similarity\"</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(l1, l2):\n",
    "    set1 = set(l1)\n",
    "    set2 = set(l2)\n",
    "\n",
    "    size_intersec = len(set1.intersection(set2))\n",
    "    size_union = len(set1.union(set2))\n",
    "\n",
    "    if size_union == 0:\n",
    "        return 0.0  #creo el condicional per evitar divisió amb denominador=0\n",
    "    else:\n",
    "        return size_intersec/size_union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write code to test your function. Your tests cases should be:\n",
    "\n",
    "1. Two arrays for which the jaccard similarity is 0.6666...\n",
    "1. Two arrays for which the jaccard similarity is 0.75\n",
    "1. Two arrays for which the jaccard similarity is 1.0\n",
    "1. Two empty arrays should have jaccard similarity 0.0\n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Replace this cell with your code testing \"jaccard_similarity\"</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st case Jaccard Similarity:  0.6666666666666666\n",
      "2nd case Jaccard Similarity:  0.75\n",
      "3rd case Jaccard Similarity:  1.0\n",
      "4th case Jaccard Similarity:  0.0\n"
     ]
    }
   ],
   "source": [
    "#1. similarity 0.6666...\n",
    "case11 = [1, 2, 3, 4, 5]\n",
    "case12 = [1, 2, 3, 4, 6]\n",
    "case1_res = jaccard_similarity(case11, case12)\n",
    "print(\"1st case Jaccard Similarity: \",case1_res)\n",
    "\n",
    "#2. similarity 0.75\n",
    "case21 = [1, 2, 3, 4]\n",
    "case22 = [1, 2, 3]\n",
    "case2_res = jaccard_similarity(case21, case22)\n",
    "print(\"2nd case Jaccard Similarity: \",case2_res)\n",
    "\n",
    "#3. similarity 1.0\n",
    "case31 = [1, 2, 3]\n",
    "case32 = [1, 2, 3]\n",
    "case3_res = jaccard_similarity(case31, case32)\n",
    "print(\"3rd case Jaccard Similarity: \",case3_res)\n",
    "\n",
    "#4. similarity 0.0\n",
    "case41 = []\n",
    "case42 = []\n",
    "case4_res = jaccard_similarity(case41, case42)\n",
    "print(\"4th case Jaccard Similarity: \",case4_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a function `clean` that cleans-up text according to this specification:\n",
    "\n",
    "1. Removing \"RT \" prefixes\n",
    "1. Converting to lowercase\n",
    "1. [Romanizing](https://en.wikipedia.org/wiki/Romanization) text, replacing \"Ñ\" by \"n\", \"ñ\" by \"n\", \"ó\" by \"o\", \"à\" by \"a\", \"l·l\" by \"ll\", and so on.\n",
    "1. Removing URLs, both \"http\" and \"https\" ones.\n",
    "1. Removing spaces at the beginning and spaces at the end with the `strip()` function.\n",
    "1. Removing anything that remains that is not a letter or digit\n",
    "1. Changing double spaces to single spaces.\n",
    "\n",
    "You can use `text.lower()` to convert to lowercase, and then `re.sub(...)` to replace parts of the text. See [Python regexps](https://docs.python.org/3/library/re.html).\n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Replace this cell with your code for function \"clean\"</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    text = re.sub(\"RT \", \"\",text) #Removing \"RT \" prefixes\n",
    "\n",
    "    text = text.lower() #Converting to lowercase\n",
    "\n",
    "    text = re.sub('ñ', 'n',text) #Romanizing text (tenint en compte que els idiomes a romanitzar són català, castellà o anglès)\n",
    "    text = re.sub('à', 'a',text)\n",
    "    text = re.sub('á', 'a',text)\n",
    "    text = re.sub('è', 'e',text)\n",
    "    text = re.sub('é', 'e',text)\n",
    "    text = re.sub('í', 'i',text)\n",
    "    text = re.sub('ó', 'o',text)\n",
    "    text = re.sub('ò', 'o',text)\n",
    "    text = re.sub('ú', 'u',text)\n",
    "    text = re.sub('ü', 'u',text)\n",
    "    text = re.sub('l·l','ll',text)\n",
    "    \n",
    "    text = re.sub(r'http\\S+', '', text) #Removing URLs, both \"http\" and \"https\" ones\n",
    "    text = re.sub(r'https\\S+', '', text) #Removes \"http\" and \"https\" followed by \\S+ (a string of non-whitespace characters)\n",
    "\n",
    "    text = text.strip() #Removing spaces at the beginning and spaces at the end with the strip() function.\n",
    "    \n",
    "    text = re.sub(r'[^a-zA-Z0-9]', ' ', text) #Removing anything that remains that is not a letter or digit\n",
    "    \n",
    "    text = re.sub(r\"\\s+\",\" \", text) #Changing multiple spaces to single spaces, using \\s+ (a string of whitespace characters)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your function by passing it five different texts including punctuation, non-Roman characters, URLs, etc. Make sure your test cases cover all the required aspects of the specification.\n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Replace this cell with your code testing function \"clean\"</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world  \n",
      "\n",
      "sally planned an annual celebration \n",
      "\n",
      "i like this websites  \n",
      "\n",
      "this text does not have special symbols  \n",
      "\n",
      "remove spaces test \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_texts = [\"RT Hello World!\"#RT Test\n",
    "             ,\"Sal·ly plàÑñed àn ànnuàl celebràtión\"#Romanizing Test\n",
    "             ,\"I like this websites: http://url1, https://url2\"#URL Test\n",
    "             ,\"This !@#$text does not have special (symbols¿¡?\"#Special Symbols Test\n",
    "             ,\" Remove  spaces  test \"]#Removing spaces at the beginning and end, and double spaces Test\n",
    "for test_text in test_texts:\n",
    "    clean_text = clean(test_text)\n",
    "    print(clean_text,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Implement an n-gram extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the function `ngrams(text,size)`, which should produce all sub-sequences of `size` words present in the text. Use the following skeleton:\n",
    "\n",
    "```python\n",
    "MIN_TOKEN_LENGTH = 3\n",
    "\n",
    "def ngrams(text, size):\n",
    "    tokens = clean(text).split()\n",
    "    ngrams = []\n",
    "    # your code here\n",
    "    return ngrams\n",
    "```\n",
    "\n",
    "Note that `ngrams` is a list, and each element of a list is a *string*.\n",
    "\n",
    "The only words you must consider in a ngram are words having at least `MIN_TOKEN_LENGTH` characters.\n",
    "\n",
    "You can use the [split](https://docs.python.org/2/library/string.html#string.split) and [join](https://docs.python.org/2/library/string.html#string.join) function of the split library. Remember that to extract elements *i* to *j* of array *a* you use `a[i:j]`.\n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Replace this cell with your code implementing function \"ngrams(text,size)\"</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_TOKEN_LENGTH = 3\n",
    "def ngrams(text, size):\n",
    "    tokens = clean(text).split() #Separem paraules text una vegada clean i guardem a tokens\n",
    "    filt_tokens = [] #Creem llista auxiliar per guardar els tokens els quals len(token)>=MIN_TOKEN_LENGTH\n",
    "    for token in tokens:\n",
    "        if len(token) >= MIN_TOKEN_LENGTH:\n",
    "            filt_tokens.append(token)\n",
    "    ngrams = [] #Llista de ngrams guardem combinacions de tamany size\n",
    "    for i in range(len(filt_tokens) - size+1):\n",
    "        ngrams.append(' '.join(filt_tokens[i:i+size]))\n",
    "        \n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your function:\n",
    "\n",
    "```python\n",
    "print(messages[9780])\n",
    "print(ngrams(messages[9780], 3))\n",
    "```\n",
    "\n",
    "Should print:\n",
    "\n",
    "```\n",
    "RT @diariARA: Comerciants xinesos donen mascaretes i gel antisèptic a Badalona per lluitar contra el coronavirus https://t.co/ybYXFxphIu\n",
    "['diariara comerciants xinesos', 'comerciants xinesos donen', 'xinesos donen mascaretes', 'donen mascaretes gel', 'mascaretes gel antiseptic', 'gel antiseptic badalona', 'antiseptic badalona per', 'badalona per lluitar', 'per lluitar contra', 'lluitar contra coronavirus']\n",
    "```\n",
    "\n",
    "Remember that `ngrams` should return a list of string, not a list of lists, so carefully check that you are returning a list of strings and not a list of lists.\n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Replace this cell with your code testing function \"ngrams\"</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @diariARA: Comerciants xinesos donen mascaretes i gel antisèptic a Badalona per lluitar contra el coronavirus https://t.co/ybYXFxphIu\n",
      "['diariara comerciants xinesos', 'comerciants xinesos donen', 'xinesos donen mascaretes', 'donen mascaretes gel', 'mascaretes gel antiseptic', 'gel antiseptic badalona', 'antiseptic badalona per', 'badalona per lluitar', 'per lluitar contra', 'lluitar contra coronavirus']\n"
     ]
    }
   ],
   "source": [
    "#Function Test\n",
    "print(messages[9780])\n",
    "print(ngrams(messages[9780], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Estimation for brute force method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code, which you should leave as-is, computes the time it takes to compare all first *limit* messages against all first *limit* messages in the array.\n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEAVE AS-IS\n",
    "\n",
    "def time_brute_force_similarities(messages, limit, ngram_size):\n",
    "    if limit > len(messages):\n",
    "        raise ValueError(\"Limit should be less than or equal than the number of messages\")\n",
    "        \n",
    "    # Start a timer\n",
    "    start = timer()\n",
    "\n",
    "    # Iterate through document identifiers\n",
    "    for docid1 in range(np.min([len(messages), limit])):\n",
    "\n",
    "        # Clean document 1 and extract ngrams\n",
    "        doc1 = clean(messages[docid1])\n",
    "        ngrams1 = ngrams(doc1, ngram_size)\n",
    "\n",
    "        # Iterate through document identifiers larger than doc2\n",
    "        for docid2 in range(docid1+1, np.min([len(messages), limit])):\n",
    "                         \n",
    "            # Clean document 2 and extract ngrams\n",
    "            doc2 = clean(messages[docid2])\n",
    "            ngrams2 = ngrams(doc2, ngram_size)\n",
    "\n",
    "            # Compute similarity\n",
    "            similarity = jaccard_similarity(ngrams1, ngrams2)\n",
    "\n",
    "    end = timer()\n",
    "    return(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the function above to create a plot in which you have in the x axis the number of messages to check, and in the y axis the time it takes to check that many messages if we use ngrams of size 4. Try with x from *1* to *2001* in increments of *150* (use the [range](https://docs.python.org/3/library/functions.html#func-range) function).\n",
    "\n",
    "In this plot, remember to include labels in both axes.\n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Replace this cell with your code for generating the requested plot. Remember to label the x and y axis.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "limits = list(range(1, 2001, 150)) #set x from 1 to 2001 in increments of 150\n",
    "list_time = [] #for each limit use time_brute_force_similarities and save the time it takes in list_time\n",
    "\n",
    "for limit in limits:\n",
    "    time_takes = time_brute_force_similarities(messages, limit, 4)\n",
    "    list_time.append(time_takes)\n",
    "\n",
    "plt.plot(limits, list_time, marker='o') #generate the plot (use of marker='o' to see the points clearly as painted circles)\n",
    "plt.title('Time vs Limit')\n",
    "plt.xlabel('Limit')\n",
    "plt.ylabel('Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Replace this cell with (1) a brief commmentary about what you see in this plot, and (2) your estimate for how long it would take to run the brute force similarity computations for the entire input matrix. Express your estimation in hours, minutes, and seconds. Justify precisely your calculations.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```(1)``` This plot shows how the increase of the limit, increases exponentially the time that it takes the use of the function time_brute_force_similarities. \n",
    "\n",
    "\n",
    "```(2)``` For the entire input matrix the limit we should pass to the function is 10000. As said before seing the plot we can guess that it is followed a quadratic function, so: y = ax<sup>2</sup> + bx + c. If we get 2 different points from the plot we can compute the approximate values of a,b and c, and then substitute the value of x. I have done the calculation in the following cell, and the estimated time for how long it would take to run the brute force similarity computations for the entire input matrix is s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "solve1: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (m,m),(m)->(m) (size 2 is different from 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [63]\u001b[0m, in \u001b[0;36m<cell line: 16>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m     y \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m*\u001b[39m(x\u001b[38;5;241m^\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m+\u001b[39m b\u001b[38;5;241m*\u001b[39mx \u001b[38;5;241m+\u001b[39m c\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m y\n\u001b[1;32m---> 16\u001b[0m time_takes_input_mat \u001b[38;5;241m=\u001b[39m \u001b[43mexpected_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlimits\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlist_time\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mlimits\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlist_time\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(time_takes_input_mat)\n",
      "Input \u001b[1;32mIn [63]\u001b[0m, in \u001b[0;36mexpected_value\u001b[1;34m(point1, point2, x)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexpected_value\u001b[39m(point1,point2,x):\n\u001b[1;32m---> 12\u001b[0m     a, b, c \u001b[38;5;241m=\u001b[39m \u001b[43mfind_quadratic_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoint1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpoint2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m     y \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m*\u001b[39m(x\u001b[38;5;241m^\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m+\u001b[39m b\u001b[38;5;241m*\u001b[39mx \u001b[38;5;241m+\u001b[39m c\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "Input \u001b[1;32mIn [63]\u001b[0m, in \u001b[0;36mfind_quadratic_parameters\u001b[1;34m(point1, point2)\u001b[0m\n\u001b[0;32m      5\u001b[0m A \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[x1\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m, x1, \u001b[38;5;241m0\u001b[39m], [x2\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m, x2, \u001b[38;5;241m0\u001b[39m],[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m]])\n\u001b[0;32m      6\u001b[0m B \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([y1, y2])\n\u001b[1;32m----> 7\u001b[0m coefficients \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m a, b, c \u001b[38;5;241m=\u001b[39m coefficients\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m a, b, c\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36msolve\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\linalg\\linalg.py:393\u001b[0m, in \u001b[0;36msolve\u001b[1;34m(a, b)\u001b[0m\n\u001b[0;32m    391\u001b[0m signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDD->D\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdd->d\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    392\u001b[0m extobj \u001b[38;5;241m=\u001b[39m get_linalg_error_extobj(_raise_linalgerror_singular)\n\u001b[1;32m--> 393\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mgufunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap(r\u001b[38;5;241m.\u001b[39mastype(result_t, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "\u001b[1;31mValueError\u001b[0m: solve1: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (m,m),(m)->(m) (size 2 is different from 3)"
     ]
    }
   ],
   "source": [
    "def find_quadratic_parameters(point1, point2):\n",
    "    x1, y1 = point1\n",
    "    x2, y2 = point2\n",
    "\n",
    "    A = np.array([[x1**2, x1, 0], [x2**2, x2, 0]])\n",
    "    B = np.array([y1, y2])\n",
    "    coefficients = np.linalg.solve(A, B)\n",
    "    a, b, c = coefficients\n",
    "    return a, b, c\n",
    "\n",
    "def expected_value(point1,point2,x):\n",
    "    a, b, c = find_quadratic_parameters(point1,point2)\n",
    "    y = a*(x^2) + b*x + c\n",
    "    return y\n",
    "\n",
    "time_takes_input_mat = expected_value((limits[6],list_time[6]), (limits[7], list_time[7]),10000)\n",
    "\n",
    "print(time_takes_input_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Computing the doc-ngram matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will compute a matrix in which every row is an ngram, and every column is a document.\n",
    "\n",
    "In real-world implementations, this is done by hashing the ngrams and then every row is an ngram *hash*; in this practice we will skip that step and work directly with one ngram per row, which is conceptually the same and easier to code.\n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Create list of all ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement code to create:\n",
    "\n",
    "* the dictionary `ngram_to_index`, which should convert an ngram to an index (a row number),\n",
    "* the dictionary `index_to_ngram`, which should convert an index to an ngram, and\n",
    "* the variable `num_distinct_ngrams` which should contain the number of distinct ngrams.\n",
    "\n",
    "You can use the following template:\n",
    "\n",
    "```python\n",
    "NGRAM_SIZE = 4\n",
    "\n",
    "ngram_to_index = {}\n",
    "index_to_ngram = {}\n",
    "next_index = 0\n",
    "\n",
    "for message in messages:\n",
    "    all_ngrams = ngrams(message, NGRAM_SIZE)\n",
    "    for ngram in all_ngrams:\n",
    "        # YOUR CODE HERE\n",
    "            \n",
    "num_distinct_ngrams = next_index\n",
    "\n",
    "print(\"There are %d distinct ngrams in the %d documents\" % (num_distinct_ngrams, len(messages)))\n",
    "```\n",
    "\n",
    "Note that the total number of n-grams may vary depending on ho you `clean()` text. In this dataset it should be about 10 times the number of documents.\n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Replace this cell with your code for creating the ngram_to_index dictionary.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 68836 distinct ngrams in the 10000 documents\n"
     ]
    }
   ],
   "source": [
    "NGRAM_SIZE = 3 #Modifico NGRAM_SIZE i MIN_TOKEN_LENGTH per dur a terme els tests de la pròxima cela\n",
    "MIN_TOKEN_LENGTH=2\n",
    "\n",
    "ngram_to_index = {}\n",
    "index_to_ngram = {}\n",
    "next_index = 0 #creem contador que usarem con index\n",
    "\n",
    "for message in messages:\n",
    "    all_ngrams = ngrams(message, NGRAM_SIZE) #Guardem tots els ngrams de message\n",
    "    for ngram in all_ngrams:\n",
    "        if ngram not in ngram_to_index: \n",
    "            ngram_to_index[ngram] = next_index #si no és a dict l'afegim amb l'index pertinent\n",
    "            index_to_ngram[next_index] = ngram #inversament de la mateixa forma per index_to_ngram\n",
    "            next_index += 1\n",
    "num_distinct_ngrams = next_index\n",
    "print(\"There are %d distinct ngrams in the %d documents\" % (num_distinct_ngrams, len(messages)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your function by printing the `ngram_to_index` of the strings `\"tancat escoles fins\"` and `\"garantir la seguretat\"`. The exact index varies,  depending on how you `clean()` text. Then, print the `index_to_ngram` of the returned index, and should give you the same string.\n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Replace this cell with your code for testing the ngram_to_index structure.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngram_to_index for 'tancat escoles fins': 977\n",
      "ngram_to_index for 'garantir la seguretat': 34\n",
      "index_to_ngram for '977': tancat escoles fins\n",
      "index_to_ngram for '34': garantir la seguretat\n"
     ]
    }
   ],
   "source": [
    "test_string1 = \"tancat escoles fins\"\n",
    "test_string2 = \"garantir la seguretat\"\n",
    "\n",
    "index1 = ngram_to_index[test_string1] #obtenim index per mitjà de string amb ngram_to_index\n",
    "index2 = ngram_to_index[test_string2]\n",
    "\n",
    "print(f\"ngram_to_index for '{test_string1}': {index1}\") \n",
    "print(f\"ngram_to_index for '{test_string2}': {index2}\")\n",
    "\n",
    "ngram1 = index_to_ngram[index1] #obtenim la mateixa string (ja que és un ngram), a partir del index\n",
    "ngram2 = index_to_ngram[index2]\n",
    "\n",
    "print(f\"index_to_ngram for '{index1}': {ngram1}\")\n",
    "print(f\"index_to_ngram for '{index2}': {ngram2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Create table ngrams x documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will create a boolean matrix named `M_ngram_doc`, where each row should be an n-gram, and each column should be a document.\n",
    "\n",
    "There might be documents having less than *NGRAM_SIZE* words and thus containing no shingles. You can skip those documents above (when reading the file), or handle them here.\n",
    "\n",
    "The next code creates an empty matrix. Leave as-is. If you run out of memory, limit the number of documents you read at the beginning of this file, for instance, read only the first 10,000 or the first 7,000 documents, and then try again.\n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix dimensions: 68836 rows (distinct shingles) x 10000 columns (distinct documents)\n"
     ]
    }
   ],
   "source": [
    "# LEAVE AS-IS\n",
    "\n",
    "# Create dense matrix in which every cell contains the value \"False\"\n",
    "M_ngram_doc = np.full((num_distinct_ngrams, len(messages)), False)\n",
    "\n",
    "# Print the number of rows and columns of this matrix\n",
    "# numpy.matrix.shape is a tuple, shape[0] is the number of rows, shape[1] the number of columns\n",
    "print(\"Matrix dimensions: %d rows (distinct shingles) x %d columns (distinct documents)\" % M_ngram_doc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the matrix `M_ngram_doc` so that position i, j (row, column) holds a `True` if document j contains ngram i, otherwise holds `False`.\n",
    "\n",
    "You can use the following template:\n",
    "\n",
    "```python\n",
    "for docid in range(len(messages)):\n",
    "    message = messages[docid]\n",
    "    all_ngrams = ngrams(message, ngram_size)\n",
    "    for ngram in all_ngrams:\n",
    "        # replace this comment with your code\n",
    "```\n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Replace this cell with your code for filling the M_ngram_doc matrix.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for docid in range(len(messages)):\n",
    "    message = messages[docid]\n",
    "    ngrams_message = ngrams(message, NGRAM_SIZE)\n",
    "    for ngram in ngrams_message:\n",
    "        ngram_index = ngram_to_index[ngram] #obtenim index a partir de ngram\n",
    "        M_ngram_doc[ngram_index, docid] = True #set that position to True because document j contains ngram i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measure the density of this matrix, as a percentage. This is the number of non-zeroes in the matrix as a percentage of the number of cells of the matrix.\n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Replace this cell with your code for printing the density of the M_ngram_doc matrix as a percentage.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix density:  0.0236 %\n"
     ]
    }
   ],
   "source": [
    "num_non_zeroes_mat = np.count_nonzero(M_ngram_doc) #This np function returns the count of non-zero elements in the array.\n",
    "num_cells_mat = M_ngram_doc.size #size returns the number of cells of the matrix in this case\n",
    "density_mat = round((num_non_zeroes_mat / num_cells_mat) * 100,4) #density of the matrix computation\n",
    "\n",
    "print(\"Matrix density: \",density_mat,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print a couple of documents (columns). All columns should be very sparse, i.e., mostly zeroes. For instance, for docid 9602 you should print something like this:\n",
    "\n",
    "```\n",
    "Positions of non-zeros in column of docid 9602 of M_ngram_doc\n",
    "\n",
    "Clean message:\n",
    " emergenciescat que puc fer i que no faqs del coronavirus a 14 de mar si us plau demanem difusio\n",
    "\n",
    "Non-zeros in corresponding row:\n",
    " ['860 (emergenciescat que puc fer)', '861 (que puc fer que)', '31071 (puc fer que faqs)', '31072 (fer que faqs del)', '31073 (que faqs del coronavirus)', '31074 (faqs del coronavirus mar)', '31075 (del coronavirus mar plau)', '31076 (coronavirus mar plau demanem)', '31077 (mar plau demanem difusio)']\n",
    " ```\n",
    "\n",
    "Note that the specific ngram ids you will get depend on your cleanup process, and that the output is in ascending order of ngram number, not in the same ordering in which the ngrams appear in the message.\n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Replace this cell with your code for printing rows 9602 and 941 of the M_ngram_doc matrix.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[4mPositions of non-zeros in column of docid  9602  of M_ngram_doc\u001b[0m\n",
      "\n",
      "Clean message for docid 9602 :\n",
      " emergenciescat que puc fer i que no faqs del coronavirus a 14 de mar si us plau demanem difusio \n",
      "\n",
      "Non-zeros in row  9602 :\n",
      "[  948  1267  1268  1269  1270  2658 40222 40223 40224 40225 40226 40227\n",
      " 40228 40229 40230]\n",
      "['948 (si us plau)', '1267 (emergenciescat que puc)', '1268 (que puc fer)', '1269 (puc fer que)', '1270 (fer que no)', '2658 (14 de mar)', '40222 (que no faqs)', '40223 (no faqs del)', '40224 (faqs del coronavirus)', '40225 (del coronavirus 14)', '40226 (coronavirus 14 de)', '40227 (de mar si)', '40228 (mar si us)', '40229 (us plau demanem)', '40230 (plau demanem difusio)']\n",
      "\n",
      "\u001b[4mPositions of non-zeros in column of docid  941  of M_ngram_doc\u001b[0m\n",
      "\n",
      "Clean message for docid 941 :\n",
      " hospiolot usem de forma responsable els recursos sanitaris 061 urgencies per coronavirus i sanitaries 012 consultes general \n",
      "\n",
      "Non-zeros in row  941 :\n",
      "['1530 (usem de forma)', '1531 (de forma responsable)', '1532 (forma responsable els)', '1533 (responsable els recursos)', '1534 (els recursos sanitaris)', '1535 (recursos sanitaris 061)', '1536 (sanitaris 061 urgencies)', '1537 (061 urgencies per)', '1538 (urgencies per coronavirus)', '1539 (per coronavirus sanitaries)', '1540 (coronavirus sanitaries 012)', '1541 (sanitaries 012 consultes)', '10570 (hospiolot usem de)', '10571 (012 consultes general)']\n"
     ]
    }
   ],
   "source": [
    "#9602\n",
    "docid1 = 9602\n",
    "print(\"\\033[4mPositions of non-zeros in column of docid \",docid1,\" of M_ngram_doc\\033[0m\\n\") #How to underline searched in the internet\n",
    "print(\"Clean message for docid\", docid1,\":\")\n",
    "print(clean(messages[docid1])) #Show message cleaned\n",
    "print(\"\\nNon-zeros in row \",docid1,\":\")\n",
    "non_zero_docid1_row = np.nonzero(M_ngram_doc[:, docid1])[0] #for column docid1 we extract the indices of the nonzero values as an array\n",
    "print(non_zero_docid1_row)                                  #np.nonzero returns a tuple and we select the first and only array using [0]\n",
    "print([f\"{pos} ({index_to_ngram[pos]})\" for pos in non_zero_docid1_row]) #print as in the example iterating in each position\n",
    "\n",
    "#941\n",
    "docid2 = 941 #same process with document id 941\n",
    "print(\"\\n\\033[4mPositions of non-zeros in column of docid \",docid2,\" of M_ngram_doc\\033[0m\\n\")\n",
    "print(\"Clean message for docid\", docid2,\":\")\n",
    "print(clean(messages[docid2]))\n",
    "print(\"\\nNon-zeros in row \",docid2,\":\")\n",
    "non_zero_docid2_row = np.nonzero(M_ngram_doc[:, docid2])[0]\n",
    "print([f\"{pos} ({index_to_ngram[pos]})\" for pos in non_zero_docid2_row])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Implement a permutation generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the function `random_permutation(k)`, which should generate a random permutation of the array `[0, 2, 3, ..., k-1]`. Tip: the function [random.shuffle](https://docs.python.org/3/library/random.html#random.shuffle) might be useful. If you want to use `range(...)`, which returns an iterator, you will need to convert the iterator to a list by using `list(range(...))`.\n",
    "\n",
    "Remember to test your code. For instance, a permutation of 20 elements should look like this:\n",
    "\n",
    "```\n",
    "[14, 10, 0, 8, 4, 12, 5, 19, 6, 9, 15, 13, 16, 2, 17, 11, 7, 3, 18, 1]\n",
    "```\n",
    "\n",
    "Every number appears only once, and all numbers from 0 to 19 appear in the permutation.\n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Replace this cell with your code for \"random_permutation\"</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_permutation(k):\n",
    "    list_to_shuffle = list(range(k)) #Creem llista amb valors del 0 a k-1\n",
    "    random.shuffle(list_to_shuffle) #Barregem els valors de la llista usant shuffle\n",
    "    return list_to_shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further test this by applying the same permutation on two lists. The code below, which you must leave as-is,  should print both lists in the same ordering, so that *alpha* is in the same position of *a*, *beta* in the same position as *b*, and so on.\n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test one permutation:\n",
      "['3 (test3)', '1 (test1)', '2 (test2)', '5 (test5)', '4 (test4)']\n",
      "['3 (beta)', '1 (alpha)', '2 (gamma)', '5 (epsilon)', '4 (delta)']\n",
      "\n",
      "Test another permutation\n",
      "['5 (test5)', '1 (test1)', '2 (test2)', '4 (test4)', '3 (test3)']\n",
      "['5 (epsilon)', '1 (alpha)', '2 (gamma)', '4 (delta)', '3 (beta)']\n"
     ]
    }
   ],
   "source": [
    "# LEAVE AS-IS\n",
    "\n",
    "# Permute a list according to a permutation\n",
    "def permuter(original_list, permutation):\n",
    "    permuted_list = []\n",
    "    for index in permutation:\n",
    "        permuted_list.append(original_list[index])\n",
    "    return permuted_list\n",
    "\n",
    "# Code for testing permutations\n",
    "original_list_1 = [\"1 (test1)\", \"2 (test2)\", \"3 (test3)\", \"4 (test4)\", \"5 (test5)\"]\n",
    "original_list_2 = [\"1 (alpha)\", \"2 (gamma)\", \"3 (beta)\", \"4 (delta)\", \"5 (epsilon)\"]\n",
    "\n",
    "print(\"Test one permutation:\")\n",
    "permutation_1 = random_permutation(5)\n",
    "print(permuter(original_list_1, permutation_1))\n",
    "print(permuter(original_list_2, permutation_1))\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Test another permutation\")\n",
    "permutation_2 = random_permutation(5)\n",
    "print(permuter(original_list_1, permutation_2))\n",
    "print(permuter(original_list_2, permutation_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Compute the signature of each document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now comes the core of the algorithm. We will create a new matrix `M_signature_doc` having a small number of rows (the *signature size*), which will be equivalent to the number of permutations we use. The number of columns will continue being the number of documents.\n",
    "\n",
    "First, we create the permutations and store them in an array of arrays named `permutations`, with the following code, which you should leave as-is.\n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permutation 0: 30673, 26876, 13667, ...\n",
      "Permutation 1: 55964, 11612, 20636, ...\n",
      "Permutation 2: 56605, 55291, 6964, ...\n",
      "Permutation 3: 19292, 38291, 25794, ...\n",
      "Permutation 4: 60498, 37186, 44732, ...\n"
     ]
    }
   ],
   "source": [
    "# Leave this code as-is\n",
    "\n",
    "NUM_PERMUTATIONS = 5\n",
    "\n",
    "permutations = []\n",
    "\n",
    "# Create the permutations\n",
    "for i in range(NUM_PERMUTATIONS):\n",
    "    permutation = random_permutation(num_distinct_ngrams)\n",
    "    permutations.append(random_permutation(num_distinct_ngrams))\n",
    "    \n",
    "# Visualize the permutations by printing their first 3 elements\n",
    "for i in range(len(permutations)):\n",
    "    permutation = permutations[i]\n",
    "    print(\"Permutation %d: %d, %d, %d, ...\" % (i, permutation[0], permutation[1], permutation[2] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you implement the signature construction. The matrix `M_signature_doc` should contain in row *i*, column *j*, the first ngram (the \"minimum\" one) that is present in a column (document), according to the order given by a permutation.\n",
    "\n",
    "This process may take a few minutes to be completed. You can use the following template:\n",
    "\n",
    "```python\n",
    "M_signature_doc = np.full((NUM_PERMUTATIONS, len(messages)), np.nan)\n",
    "\n",
    "# Find the first ngram in a document, according to a permutation\n",
    "def find_first_one(docid, permutation):\n",
    "    for shingle_id in permutation:\n",
    "        if M_ngram_doc[shingle_id, docid] == True:\n",
    "            return shingle_id\n",
    "    return -1\n",
    "\n",
    "# Create permutations\n",
    "for permutation_num in range(NUM_PERMUTATIONS):\n",
    "    print(\"Creating signatures for permutation %d/%d\" % (permutation_num+1, NUM_PERMUTATIONS))\n",
    "    permutation = permutations[permutation_num]\n",
    "    for docid in range(len(messages)):\n",
    "        if docid % 1000 == 0:\n",
    "            print(\"- Scanning document %d of %d\" % (docid, len(messages)))\n",
    "        # replace this comment with your code\n",
    "```\n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Replace this cell with your code for creating M_signature_doc</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating signatures for permutation 1/5\n",
      "- Scanning document 0 of 10000\n",
      "- Scanning document 1000 of 10000\n",
      "- Scanning document 2000 of 10000\n",
      "- Scanning document 3000 of 10000\n",
      "- Scanning document 4000 of 10000\n",
      "- Scanning document 5000 of 10000\n",
      "- Scanning document 6000 of 10000\n",
      "- Scanning document 7000 of 10000\n",
      "- Scanning document 8000 of 10000\n",
      "- Scanning document 9000 of 10000\n",
      "Creating signatures for permutation 2/5\n",
      "- Scanning document 0 of 10000\n",
      "- Scanning document 1000 of 10000\n",
      "- Scanning document 2000 of 10000\n",
      "- Scanning document 3000 of 10000\n",
      "- Scanning document 4000 of 10000\n",
      "- Scanning document 5000 of 10000\n",
      "- Scanning document 6000 of 10000\n",
      "- Scanning document 7000 of 10000\n",
      "- Scanning document 8000 of 10000\n",
      "- Scanning document 9000 of 10000\n",
      "Creating signatures for permutation 3/5\n",
      "- Scanning document 0 of 10000\n",
      "- Scanning document 1000 of 10000\n",
      "- Scanning document 2000 of 10000\n",
      "- Scanning document 3000 of 10000\n",
      "- Scanning document 4000 of 10000\n",
      "- Scanning document 5000 of 10000\n",
      "- Scanning document 6000 of 10000\n",
      "- Scanning document 7000 of 10000\n",
      "- Scanning document 8000 of 10000\n",
      "- Scanning document 9000 of 10000\n",
      "Creating signatures for permutation 4/5\n",
      "- Scanning document 0 of 10000\n",
      "- Scanning document 1000 of 10000\n",
      "- Scanning document 2000 of 10000\n",
      "- Scanning document 3000 of 10000\n",
      "- Scanning document 4000 of 10000\n",
      "- Scanning document 5000 of 10000\n",
      "- Scanning document 6000 of 10000\n",
      "- Scanning document 7000 of 10000\n",
      "- Scanning document 8000 of 10000\n",
      "- Scanning document 9000 of 10000\n",
      "Creating signatures for permutation 5/5\n",
      "- Scanning document 0 of 10000\n",
      "- Scanning document 1000 of 10000\n",
      "- Scanning document 2000 of 10000\n",
      "- Scanning document 3000 of 10000\n",
      "- Scanning document 4000 of 10000\n",
      "- Scanning document 5000 of 10000\n",
      "- Scanning document 6000 of 10000\n",
      "- Scanning document 7000 of 10000\n",
      "- Scanning document 8000 of 10000\n",
      "- Scanning document 9000 of 10000\n"
     ]
    }
   ],
   "source": [
    "M_signature_doc = np.full((NUM_PERMUTATIONS, len(messages)), np.nan)\n",
    "\n",
    "def find_first_one(docid, permutation):\n",
    "    for shingle_id in permutation:\n",
    "        if M_ngram_doc[shingle_id, docid] == True:\n",
    "            return shingle_id\n",
    "    return -1\n",
    "\n",
    "# Create permutations\n",
    "for permutation_num in range(NUM_PERMUTATIONS):\n",
    "    print(\"Creating signatures for permutation %d/%d\" % (permutation_num+1, NUM_PERMUTATIONS))\n",
    "    permutation = permutations[permutation_num]\n",
    "    for docid in range(len(messages)):\n",
    "        if docid % 1000 == 0:\n",
    "            print(\"- Scanning document %d of %d\" % (docid, len(messages)))\n",
    "        \n",
    "        first_ngram = find_first_one(docid, permutation) #Usem la funció donada passant per paràmetre docid i la permutació\n",
    "        \n",
    "        M_signature_doc[permutation_num, docid] = first_ngram #Guardem el primer ngram a matriu a la posició [permutation_num, docid]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your code by checking the signatures of two documents that are near-duplicates,using the next code, which you should leave as-is. Being near-duplicates, we expect these should have many ngrams in common, and hence, with high probability they will have many elements in common in their signatures.\n",
    "\n",
    "Note that your ngrams and signatures vectors might be different than what we show here, given the differences in cleaning procedures and the randomness of the permutations.\n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document #385\n",
      "Message       : RT @gencat: 🔴 El @govern de la @gencat anuncia el #confinament de tot Catalunya.\n",
      "\n",
      "Davant l’emergència de la #COVID19, el missatge és clau:…\n",
      "Clean message :  gencat el govern de la gencat anuncia el confinament de tot catalunya davant l emergencia de la covid19 el missatge es clau \n",
      "Ngrams        : [62, 3437, 3564, 4227, 5043, 5044, 5045, 5046, 5047, 5048, 5049, 5050, 5051, 5052, 5053, 5054, 5055, 5056, 5057]\n",
      "Signature     : [5054.0, 5045.0, 5052.0, 4227.0, 4227.0]\n",
      "\n",
      "Document #627\n",
      "Message       : PROCICAT_CORONAVIRUS. El @govern de la @gencat anuncia el #confinament de tot Catalunya. Davant l’emergència de la #COVID19, el missatge és clau: limitar la mobilitat ajudarà a evitar la propagació del #coronavirus. Evitem desplaçaments i reduïm la vida social #JoEmQuedoACasa\n",
      "Clean message : procicat coronavirus el govern de la gencat anuncia el confinament de tot catalunya davant l emergencia de la covid19 el missatge es clau limitar la mobilitat ajudara a evitar la propagacio del coronavirus evitem despla aments i redu m la vida social joemquedoacasa\n",
      "Ngrams        : [62, 245, 246, 333, 1605, 1606, 1607, 1608, 3437, 3564, 4227, 5044, 5045, 5046, 5047, 5048, 5049, 5050, 5051, 5052, 5053, 5054, 5055, 5056, 5057, 7452, 7453, 7454, 7455, 7456, 7457, 7458, 7459, 7460, 7461, 7462, 7463]\n",
      "Signature     : [5054.0, 5045.0, 5052.0, 4227.0, 333.0]\n"
     ]
    }
   ],
   "source": [
    "# Leave this code as-is\n",
    "\n",
    "def extract_ngrams(docid):\n",
    "    return [x for x in range(num_distinct_ngrams) if M_ngram_doc[x, docid] == True]\n",
    "\n",
    "def extract_signature(docid):\n",
    "    return [M_signature_doc[x, docid] for x in range(NUM_PERMUTATIONS)]\n",
    "\n",
    "def print_sig(messages, M_ngram_doc, M_signature_doc, i):\n",
    "    print(\"Document #%d\" % i)\n",
    "    print(\"Message       : %s\" % messages[i])\n",
    "    print(\"Clean message : %s\" % clean(messages[i]))\n",
    "    print(\"Ngrams        : %s\" % extract_ngrams(i))\n",
    "    print(\"Signature     : %s\" % extract_signature(i))\n",
    "\n",
    "        \n",
    "i = 385\n",
    "j = 627\n",
    "\n",
    "print_sig(messages, M_ngram_doc, M_signature_doc, i )\n",
    "\n",
    "print()\n",
    "\n",
    "print_sig(messages, M_ngram_doc, M_signature_doc, j )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Compare all pairs of signatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to compare all documents by their signatures, instead of by their content.\n",
    "\n",
    "We will consider that if two documents have *similarity == 1.0* they are a *full signature match*, and if two documents have *0.2 < similarity < 1.0* they are a *partial signature match*. In both cases, this may mean the documents are duplicates or near duplicates.\n",
    "\n",
    "Write code to compare all pairs of documents. Use the following template:\n",
    "\n",
    "```python\n",
    "is_possible_duplicate = {}\n",
    "\n",
    "# Iterate through all documents\n",
    "for docid1 in range(len(messages)):\n",
    "\n",
    "     # Do not examine again a document that is a possible duplicate\n",
    "    if docid not in is_possible_duplicate:\n",
    "\n",
    "        # Counters for full and partial signature matches\n",
    "        count_sig_full_matches = 0\n",
    "        count_sig_partial_matches = 0\n",
    "\n",
    "        # Extract the signature of the doc1\n",
    "        signature1 = extract_signature(docid1)\n",
    "        if docid1 % 500 == 0:\n",
    "            print(\"%d/%d documents scanned\" % (docid1, len(messages)))\n",
    "\n",
    "        # Iterate through documents with docid larger than doc1\n",
    "        for docid2 in range(docid1+1, len(messages)):\n",
    "\n",
    "            # If this has not already been marked as duplicate of another document\n",
    "            if docid2 not in is_possible_duplicate:\n",
    "\n",
    "                # Extract signature of doc2\n",
    "                signature2 = extract_signature(docid2)\n",
    "\n",
    "                # REPLACE THIS COMMENT WITH YOUR CODE:\n",
    "                # - Increase count_sig_full_matches and count_sig_partial_matches as needed\n",
    "                # - Include docid2 in is_possible_duplicate if needed\n",
    "\n",
    "        # REPLACE THIS COMMENT WITH YOUR CODE\n",
    "        # - If the number of partial matches plus full matches exceeds a threshold\n",
    "        #   print the document doc1 and indicate how many matches of each type it has\n",
    "```\n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Replace this cell with your code for comparing all signatures; print all documents that have at least 50 signature matches, considering both full matches and partial matches.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/10000 documents scanned\n",
      "\n",
      "Document 16 has 71 full matches and 26 partial matches.\n",
      "RT @emergenciescat: ⚠️ Es demana a la ciutadania limitar al màxim i, si es pot, EVITAR DESPLAÇAMENTS de cap de setmana. Tot el que sigui ma…\n",
      "\n",
      "Document 19 has 4 full matches and 46 partial matches.\n",
      "RT @emergenciescat: El comitè tècnic del Pla #PROCICAT  per evitar la propagació del #coronavirus ha proposat al Govern que ordeni el cessa…\n",
      "500/10000 documents scanned\n",
      "1000/10000 documents scanned\n",
      "1500/10000 documents scanned\n",
      "2000/10000 documents scanned\n",
      "2500/10000 documents scanned\n"
     ]
    }
   ],
   "source": [
    "is_possible_duplicate = {}\n",
    "\n",
    "MATCH_THRESHOLD = 50\n",
    "\n",
    "# Iterate through all documents\n",
    "for docid1 in range(len(messages)):\n",
    "\n",
    "    # Do not examine again a document that is a possible duplicate\n",
    "    if docid1 not in is_possible_duplicate:\n",
    "\n",
    "        # Counters for full and partial signature matches\n",
    "        count_sig_full_matches = 0\n",
    "        count_sig_partial_matches = 0\n",
    "\n",
    "        # Extract the signature of the doc1\n",
    "        signature1 = extract_signature(docid1)\n",
    "        if docid1 % 500 == 0:\n",
    "            print(\"%d/%d documents scanned\" % (docid1, len(messages)))\n",
    "        # Iterate through documents with docid larger than doc1\n",
    "        for docid2 in range(docid1+1, len(messages)):\n",
    "\n",
    "            # If this has not already been marked as duplicate of another document\n",
    "            if docid2 not in is_possible_duplicate:\n",
    "\n",
    "                # Extract signature of doc2\n",
    "                signature2 = extract_signature(docid2)\n",
    "\n",
    "                # - Increase count_sig_full_matches and count_sig_partial_matches as needed\n",
    "                full_match = (signature1 == signature2)\n",
    "                partial_match = any(x == y for x, y in zip(signature1, signature2))\n",
    "\n",
    "                if full_match:\n",
    "                    count_sig_full_matches += 1\n",
    "                elif partial_match:\n",
    "                    count_sig_partial_matches += 1\n",
    "\n",
    "                # - Include docid2 in is_possible_duplicate if needed\n",
    "                if count_sig_full_matches + count_sig_partial_matches >= MATCH_THRESHOLD:\n",
    "                    is_possible_duplicate[docid1] = True\n",
    "                    is_possible_duplicate[docid2] = True\n",
    "\n",
    "        # - If the number of partial matches plus full matches exceeds a threshold\n",
    "        if count_sig_full_matches + count_sig_partial_matches >= MATCH_THRESHOLD:\n",
    "            #   print the document doc1 and indicate how many matches of each type it has\n",
    "            print(f\"\\nDocument {docid1} has {count_sig_full_matches} full matches and {count_sig_partial_matches} partial matches.\")\n",
    "            print(messages[docid1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Replace this cell with a brief commentary, based on the results above, about one tweet that has a substantial number of complete matches, but few partial matches. Include the full text of the original tweet. Comment on why you believe this tweet is not being changed much when copied or re-tweeted.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Replace this cell with a brief commentary, based on the results above, about one tweet that has a substantial number of partial matches, but fewer complete matches. Include the full text of the original tweet and one near duplicate (that cannot be identical to the original tweet).</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DELIVER (individually)\n",
    "\n",
    "Remember to read the section on \"delivering your code\" in the [course evaluation guidelines](https://github.com/chatox/data-mining-course/blob/master/upf/upf-evaluation.md).\n",
    "\n",
    "Deliver a zip file containing:\n",
    "\n",
    "* This notebook\n",
    "\n",
    "## Extra points available\n",
    "\n",
    "For more learning and extra points, compare what happens with 3 different ngram sizes (2-grams, 3-grams, 4-grams) in terms of the efficiency (speed) and effectiveness (accuracy). You can include plots for efficiency, and examples for effectiveness.\n",
    "\n",
    "**Note:** if you go for the extra points, add ``<font size=\"+2\" color=\"blue\">Additional results: various ngram sizes</font>`` at the top of your notebook.\n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+2\" color=\"#003300\">I hereby declare that, except for the code provided by the course instructors, all of my code, report, and figures were produced by myself.</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
